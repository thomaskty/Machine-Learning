{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %conda install pandas -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %conda install prettytable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "def table(input_dataframe):\n",
    "    \"\"\"\n",
    "    This function takes a Pandas DataFrame or Series and displays it as a PrettyTable.\n",
    "    It also supports multi-index DataFrames and groupby operations with aggregated columns.\n",
    "    Index values are retained and displayed in the table.\n",
    "    \"\"\"\n",
    "    from prettytable import PrettyTable\n",
    "    import pandas as pd\n",
    "\n",
    "    # Make a deep copy of the input DataFrame or Series\n",
    "    df_or_series = input_dataframe.copy()\n",
    "\n",
    "    # If the input is a Pandas Series\n",
    "    if isinstance(df_or_series, pd.Series):\n",
    "        index_name = df_or_series.index.name or 'index'  # Default to 'index' if index has no name\n",
    "        series_name = df_or_series.name or 'value'  # Default to 'value' if Series has no name\n",
    "        df_or_series = df_or_series.reset_index()  # Reset the index\n",
    "        df_or_series.columns = [index_name, series_name]  # Use dynamic column names\n",
    "\n",
    "    # If the input is a DataFrame\n",
    "    elif isinstance(df_or_series, pd.DataFrame):\n",
    "        # If the DataFrame has a multi-index\n",
    "        if isinstance(df_or_series.index, pd.MultiIndex):\n",
    "            df_or_series.reset_index(inplace=True)\n",
    "        else:\n",
    "            # Convert the index to a column if not already part of the DataFrame\n",
    "            df_or_series.reset_index(inplace=True)\n",
    "\n",
    "    # Create a PrettyTable instance\n",
    "    table = PrettyTable()\n",
    "\n",
    "    # Set the column names (field names) to match the DataFrame columns\n",
    "    table.field_names = df_or_series.columns.tolist()\n",
    "\n",
    "    # Add rows from the DataFrame to the PrettyTable\n",
    "    for row in df_or_series.itertuples(index=False):\n",
    "        table.add_row(row)\n",
    "\n",
    "    # Print the PrettyTable\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sample_datasets/blackfriday.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(537577, 12)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['User_ID', 'Product_ID', 'Gender', 'Age', 'Occupation', 'City_Category',\n",
      "       'Stay_In_Current_City_Years', 'Marital_Status', 'Product_Category_1',\n",
      "       'Product_Category_2', 'Product_Category_3', 'Purchase'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['user_id', 'product_id', 'gender', 'age', 'occupation', 'city_category',\n",
      "       'stay_in_current_city_years', 'marital_status', 'product_category_1',\n",
      "       'product_category_2', 'product_category_3', 'purchase'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df.columns = [i.lower().replace(' ','_') for i in df.columns]\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+------------+----------+------------+--------------------+--------------------+--------------------+\n",
      "| index | user_id | product_id | purchase | occupation | product_category_1 | product_category_2 | product_category_3 |\n",
      "+-------+---------+------------+----------+------------+--------------------+--------------------+--------------------+\n",
      "|   0   | 1000001 | P00069042  |   8370   |     10     |         3          |        nan         |        nan         |\n",
      "|   1   | 1000001 | P00248942  |  15200   |     10     |         1          |        6.0         |        14.0        |\n",
      "|   2   | 1000001 | P00087842  |   1422   |     10     |         12         |        nan         |        nan         |\n",
      "|   3   | 1000001 | P00085442  |   1057   |     10     |         12         |        14.0        |        nan         |\n",
      "|   4   | 1000002 | P00285442  |   7969   |     16     |         8          |        nan         |        nan         |\n",
      "+-------+---------+------------+----------+------------+--------------------+--------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "table(df[['user_id','product_id','purchase','occupation','product_category_1','product_category_2','product_category_3']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'city_category'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.city_category.value_counts().index.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------+\n",
      "| city_category | count  |\n",
      "+---------------+--------+\n",
      "|       B       | 226493 |\n",
      "|       C       | 166446 |\n",
      "|       A       | 144638 |\n",
      "+---------------+--------+\n"
     ]
    }
   ],
   "source": [
    "table(df.city_category.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+\n",
      "| occupation | count |\n",
      "+------------+-------+\n",
      "|     4      | 70862 |\n",
      "|     0      | 68120 |\n",
      "|     7      | 57806 |\n",
      "|     1      | 45971 |\n",
      "|     17     | 39090 |\n",
      "|     20     | 32910 |\n",
      "|     12     | 30423 |\n",
      "|     14     | 26712 |\n",
      "|     2      | 25845 |\n",
      "|     16     | 24790 |\n",
      "|     6      | 19822 |\n",
      "|     3      | 17366 |\n",
      "|     10     | 12623 |\n",
      "|     5      | 11985 |\n",
      "|     15     | 11812 |\n",
      "|     11     | 11338 |\n",
      "|     19     |  8352 |\n",
      "|     13     |  7548 |\n",
      "|     18     |  6525 |\n",
      "|     9      |  6153 |\n",
      "|     8      |  1524 |\n",
      "+------------+-------+\n"
     ]
    }
   ],
   "source": [
    "table(df.occupation.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Grouping - aggregation/sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+--------------------+---------------------+----------------------+-----------------------+\n",
      "| ('city_category', '') | ('occupation', '') | ('purchase', 'sum') | ('purchase', 'mean') | ('purchase', 'count') |\n",
      "+-----------------------+--------------------+---------------------+----------------------+-----------------------+\n",
      "|           A           |         0          |      164080740      |   8919.37051532942   |         18396         |\n",
      "|           A           |         1          |      108803572      |  8778.021137555466   |         12395         |\n",
      "|           A           |         2          |       76427056      |   8588.27463759973   |          8899         |\n",
      "|           A           |         3          |       49011902      |  8821.436645068394   |          5556         |\n",
      "|           A           |         4          |      214506091      |  8989.443089430893   |         23862         |\n",
      "|           A           |         5          |       20966920      |  8937.306052855925   |          2346         |\n",
      "|           A           |         6          |       34156542      |  9301.890522875818   |          3672         |\n",
      "|           A           |         7          |      140383356      |  8883.897987596507   |         15802         |\n",
      "|           A           |         8          |       1144331       |       11443.31       |          100          |\n",
      "|           A           |         9          |       6298388       |  8984.861626248217   |          701          |\n",
      "|           A           |         10         |       18943119      |  8661.691358024691   |          2187         |\n",
      "|           A           |         11         |       22544322      |  9381.740324594257   |          2403         |\n",
      "|           A           |         12         |       65733668      |   9496.34036405663   |          6922         |\n",
      "|           A           |         13         |       3334734       |     8684.203125      |          384          |\n",
      "|           A           |         14         |       72267923      |  9482.734942920877   |          7621         |\n",
      "|           A           |         15         |       29421256      |  9807.085333333333   |          3000         |\n",
      "|           A           |         16         |       55918396      |  9450.464086530337   |          5917         |\n",
      "|           A           |         17         |       73597023      |  9140.216467958271   |          8052         |\n",
      "|           A           |         18         |       14130776      |  8870.543628374136   |          1593         |\n",
      "|           A           |         19         |       18497734      |  8362.447558770344   |          2212         |\n",
      "|           A           |         20         |      105500948      |  8361.146615945474   |         12618         |\n",
      "|           B           |         0          |      266483416      |  9077.647363401009   |         29356         |\n",
      "|           B           |         1          |      169927659      |  8802.261538461538   |         19305         |\n",
      "|           B           |         2          |       98171236      |   8846.64648103091   |         11097         |\n",
      "|           B           |         3          |       63585551      |  9281.207269011824   |          6851         |\n",
      "|           B           |         4          |      266850565      |  9107.216989181257   |         29301         |\n",
      "|           B           |         5          |       59570514      |  9132.379886555265   |          6523         |\n",
      "|           B           |         6          |       97749478      |  9151.715944199981   |         10681         |\n",
      "|           B           |         7          |      213446917      |  9442.047111386357   |         22606         |\n",
      "|           B           |         8          |       7840209       |  9480.301088270859   |          827          |\n",
      "|           B           |         9          |       27278608      |  8580.877005347593   |          3179         |\n",
      "|           B           |         10         |       36974362      |  8952.630024213075   |          4130         |\n",
      "|           B           |         11         |       47757633      |  8703.778567523237   |          5487         |\n",
      "|           B           |         12         |      126966316      |  9866.059212059989   |         12869         |\n",
      "|           B           |         13         |       20625071      |  8844.370068610635   |          2332         |\n",
      "|           B           |         14         |      102998380      |  9322.807748008689   |         11048         |\n",
      "|           B           |         15         |       49666492      |  9788.429641308632   |          5074         |\n",
      "|           B           |         16         |       98095511      |  9201.342369383736   |         10661         |\n",
      "|           B           |         17         |      153965812      |  9814.240948495666   |         15688         |\n",
      "|           B           |         18         |       18472111      |   8817.23675417661   |          2095         |\n",
      "|           B           |         19         |       29965550      |   8899.77724977725   |          3367         |\n",
      "|           B           |         20         |      127040221      |  9063.942708333334   |         14016         |\n",
      "|           C           |         0          |      195250655      |  9586.147633542812   |         20368         |\n",
      "|           C           |         1          |      135821598      |  9517.314694134959   |         14271         |\n",
      "|           C           |         2          |       58677101      |  10031.988545050435  |          5849         |\n",
      "|           C           |         3          |       47830997      |  9645.290784432345   |          4959         |\n",
      "|           C           |         4          |      176173737      |  9953.880840725466   |         17699         |\n",
      "|           C           |         5          |       31987921      |  10265.699935815148  |          3116         |\n",
      "|           C           |         6          |       53159677      |  9720.182300237704   |          5469         |\n",
      "|           C           |         7          |      195452471      |  10075.908392617795  |         19398         |\n",
      "|           C           |         8          |       5610059       |  9397.083752093802   |          597          |\n",
      "|           C           |         9          |       20042313      |  8817.559612846459   |          2273         |\n",
      "|           C           |         10         |       58356473      |   9254.11877576911   |          6306         |\n",
      "|           C           |         11         |       35135404      |  10190.082366589328  |          3448         |\n",
      "|           C           |         12         |      107972121      |  10155.391365688487  |         10632         |\n",
      "|           C           |         13         |       47175939      |  9763.232408940397   |          4832         |\n",
      "|           C           |         14         |       80328442      |   9987.37311948278   |          8043         |\n",
      "|           C           |         15         |       37452278      |  10019.336008560727  |          3738         |\n",
      "|           C           |         16         |       80428423      |  9794.011568436434   |          8212         |\n",
      "|           C           |         17         |      159677520      |  10402.444299674267  |         15350         |\n",
      "|           C           |         18         |       27646819      |  9745.089531194924   |          2837         |\n",
      "|           C           |         19         |       24652205      |  8890.084745762711   |          2773         |\n",
      "|           C           |         20         |       59735816      |  9518.135117909496   |          6276         |\n",
      "+-----------------------+--------------------+---------------------+----------------------+-----------------------+\n"
     ]
    }
   ],
   "source": [
    "group_df = df.groupby(['city_category','occupation']).agg({'purchase':['sum','mean','count']})\n",
    "table(group_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+--------------------+---------------------+----------------------+-----------------------+\n",
      "| ('city_category', '') | ('occupation', '') | ('purchase', 'sum') | ('purchase', 'mean') | ('purchase', 'count') |\n",
      "+-----------------------+--------------------+---------------------+----------------------+-----------------------+\n",
      "|           A           |         4          |      214506091      |  8989.443089430893   |         23862         |\n",
      "|           A           |         0          |      164080740      |   8919.37051532942   |         18396         |\n",
      "|           A           |         7          |      140383356      |  8883.897987596507   |         15802         |\n",
      "|           A           |         1          |      108803572      |  8778.021137555466   |         12395         |\n",
      "|           A           |         20         |      105500948      |  8361.146615945474   |         12618         |\n",
      "|           A           |         2          |       76427056      |   8588.27463759973   |          8899         |\n",
      "|           A           |         17         |       73597023      |  9140.216467958271   |          8052         |\n",
      "|           A           |         14         |       72267923      |  9482.734942920877   |          7621         |\n",
      "|           A           |         12         |       65733668      |   9496.34036405663   |          6922         |\n",
      "|           A           |         16         |       55918396      |  9450.464086530337   |          5917         |\n",
      "|           A           |         3          |       49011902      |  8821.436645068394   |          5556         |\n",
      "|           A           |         6          |       34156542      |  9301.890522875818   |          3672         |\n",
      "|           A           |         15         |       29421256      |  9807.085333333333   |          3000         |\n",
      "|           A           |         11         |       22544322      |  9381.740324594257   |          2403         |\n",
      "|           A           |         5          |       20966920      |  8937.306052855925   |          2346         |\n",
      "|           A           |         10         |       18943119      |  8661.691358024691   |          2187         |\n",
      "|           A           |         19         |       18497734      |  8362.447558770344   |          2212         |\n",
      "|           A           |         18         |       14130776      |  8870.543628374136   |          1593         |\n",
      "|           A           |         9          |       6298388       |  8984.861626248217   |          701          |\n",
      "|           A           |         13         |       3334734       |     8684.203125      |          384          |\n",
      "|           A           |         8          |       1144331       |       11443.31       |          100          |\n",
      "|           B           |         4          |      266850565      |  9107.216989181257   |         29301         |\n",
      "|           B           |         0          |      266483416      |  9077.647363401009   |         29356         |\n",
      "|           B           |         7          |      213446917      |  9442.047111386357   |         22606         |\n",
      "|           B           |         1          |      169927659      |  8802.261538461538   |         19305         |\n",
      "|           B           |         17         |      153965812      |  9814.240948495666   |         15688         |\n",
      "|           B           |         20         |      127040221      |  9063.942708333334   |         14016         |\n",
      "|           B           |         12         |      126966316      |  9866.059212059989   |         12869         |\n",
      "|           B           |         14         |      102998380      |  9322.807748008689   |         11048         |\n",
      "|           B           |         2          |       98171236      |   8846.64648103091   |         11097         |\n",
      "|           B           |         16         |       98095511      |  9201.342369383736   |         10661         |\n",
      "|           B           |         6          |       97749478      |  9151.715944199981   |         10681         |\n",
      "|           B           |         3          |       63585551      |  9281.207269011824   |          6851         |\n",
      "|           B           |         5          |       59570514      |  9132.379886555265   |          6523         |\n",
      "|           B           |         15         |       49666492      |  9788.429641308632   |          5074         |\n",
      "|           B           |         11         |       47757633      |  8703.778567523237   |          5487         |\n",
      "|           B           |         10         |       36974362      |  8952.630024213075   |          4130         |\n",
      "|           B           |         19         |       29965550      |   8899.77724977725   |          3367         |\n",
      "|           B           |         9          |       27278608      |  8580.877005347593   |          3179         |\n",
      "|           B           |         13         |       20625071      |  8844.370068610635   |          2332         |\n",
      "|           B           |         18         |       18472111      |   8817.23675417661   |          2095         |\n",
      "|           B           |         8          |       7840209       |  9480.301088270859   |          827          |\n",
      "|           C           |         7          |      195452471      |  10075.908392617795  |         19398         |\n",
      "|           C           |         0          |      195250655      |  9586.147633542812   |         20368         |\n",
      "|           C           |         4          |      176173737      |  9953.880840725466   |         17699         |\n",
      "|           C           |         17         |      159677520      |  10402.444299674267  |         15350         |\n",
      "|           C           |         1          |      135821598      |  9517.314694134959   |         14271         |\n",
      "|           C           |         12         |      107972121      |  10155.391365688487  |         10632         |\n",
      "|           C           |         16         |       80428423      |  9794.011568436434   |          8212         |\n",
      "|           C           |         14         |       80328442      |   9987.37311948278   |          8043         |\n",
      "|           C           |         20         |       59735816      |  9518.135117909496   |          6276         |\n",
      "|           C           |         2          |       58677101      |  10031.988545050435  |          5849         |\n",
      "|           C           |         10         |       58356473      |   9254.11877576911   |          6306         |\n",
      "|           C           |         6          |       53159677      |  9720.182300237704   |          5469         |\n",
      "|           C           |         3          |       47830997      |  9645.290784432345   |          4959         |\n",
      "|           C           |         13         |       47175939      |  9763.232408940397   |          4832         |\n",
      "|           C           |         15         |       37452278      |  10019.336008560727  |          3738         |\n",
      "|           C           |         11         |       35135404      |  10190.082366589328  |          3448         |\n",
      "|           C           |         5          |       31987921      |  10265.699935815148  |          3116         |\n",
      "|           C           |         18         |       27646819      |  9745.089531194924   |          2837         |\n",
      "|           C           |         19         |       24652205      |  8890.084745762711   |          2773         |\n",
      "|           C           |         9          |       20042313      |  8817.559612846459   |          2273         |\n",
      "|           C           |         8          |       5610059       |  9397.083752093802   |          597          |\n",
      "+-----------------------+--------------------+---------------------+----------------------+-----------------------+\n"
     ]
    }
   ],
   "source": [
    "# for each city category : sort the purchase value in descending order \n",
    "sorted_grouped = group_df.sort_values(['city_category',('purchase','sum')], ascending=[True, False])\n",
    "table(sorted_grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching the nth item after groupby/orderby "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------------------+--------------------+---------------------+----------------------+-----------------------+\n",
      "| ('index', '') | ('city_category', '') | ('occupation', '') | ('purchase', 'sum') | ('purchase', 'mean') | ('purchase', 'count') |\n",
      "+---------------+-----------------------+--------------------+---------------------+----------------------+-----------------------+\n",
      "|       0       |           A           |         0          |      164080740      |   8919.37051532942   |         18396         |\n",
      "|       1       |           B           |         0          |      266483416      |  9077.647363401009   |         29356         |\n",
      "|       2       |           C           |         0          |      195250655      |  9586.147633542812   |         20368         |\n",
      "+---------------+-----------------------+--------------------+---------------------+----------------------+-----------------------+\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Extract the second largest purchase for each City_Category\n",
    "result = (\n",
    "    sorted_grouped.groupby('city_category')\n",
    "    .nth(1)  # Get the second row (index 1) in each group\n",
    "    .reset_index()\n",
    ")\n",
    "table(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groupby orderby - assigning ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+----------+-------------------+--------+------+\n",
      "| index |    City    | Employee |     Job_Title     | Salary | Rank |\n",
      "+-------+------------+----------+-------------------+--------+------+\n",
      "|   0   | California |    E1    |   Data Scientist  | 120000 | 1.0  |\n",
      "|   1   | California |    E2    |   Data Scientist  | 120000 | 1.0  |\n",
      "|   2   | California |    E3    |   Data Scientist  | 110000 | 2.0  |\n",
      "|   3   | California |    E4    |   Data Scientist  | 100000 | 3.0  |\n",
      "|   4   |  New York  |    E5    |   Data Scientist  | 130000 | 1.0  |\n",
      "|   5   |  New York  |    E6    |   Data Scientist  | 125000 | 2.0  |\n",
      "|   6   |   Texas    |    E7    |   Data Scientist  | 115000 | 1.0  |\n",
      "|   7   |   Texas    |    E8    |   Data Scientist  | 115000 | 1.0  |\n",
      "|   8   |   Texas    |    E9    | Software Engineer | 140000 | 1.0  |\n",
      "|   9   |   Texas    |   E10    | Software Engineer | 135000 | 2.0  |\n",
      "|   10  | California |   E11    | Software Engineer | 150000 | 1.0  |\n",
      "|   11  | California |   E12    | Software Engineer | 145000 | 2.0  |\n",
      "|   12  |  New York  |   E13    |      Manager      | 160000 | 1.0  |\n",
      "|   13  |  New York  |   E14    |      Manager      | 155000 | 2.0  |\n",
      "|   14  |   Texas    |   E15    |      Manager      | 90000  | 1.0  |\n",
      "|   15  |   Texas    |   E16    |      Manager      | 85000  | 2.0  |\n",
      "+-------+------------+----------+-------------------+--------+------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Expanded Sample Dataset\n",
    "data = {\n",
    "    'City': [\n",
    "        'California', 'California', 'California', 'California', 'New York', 'New York',\n",
    "        'Texas', 'Texas', 'Texas', 'Texas', 'California', 'California', 'New York',\n",
    "        'New York', 'Texas', 'Texas'\n",
    "    ],\n",
    "    'Employee': [\n",
    "        'E1', 'E2', 'E3', 'E4', 'E5', 'E6', \n",
    "        'E7', 'E8', 'E9', 'E10', 'E11', 'E12', 'E13',\n",
    "        'E14', 'E15', 'E16'\n",
    "    ],\n",
    "    'Job_Title': [\n",
    "        'Data Scientist', 'Data Scientist', 'Data Scientist', 'Data Scientist', \n",
    "        'Data Scientist', 'Data Scientist', 'Data Scientist', 'Data Scientist', \n",
    "        'Software Engineer', 'Software Engineer', 'Software Engineer', \n",
    "        'Software Engineer', 'Manager', 'Manager', 'Manager', 'Manager'\n",
    "    ],\n",
    "    'Salary': [\n",
    "        120000, 120000, 110000, 100000, 130000, 125000, \n",
    "        115000, 115000, 140000, 135000, 150000, 145000, 160000, 155000, 90000, 85000\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Assign ranks within each City and Job_Title based on Salary in descending order\n",
    "df['Rank'] = (\n",
    "    df.groupby(['City', 'Job_Title'])['Salary']\n",
    "    .rank(ascending=False, method='dense')  # Dense ranking: same salary gets same rank\n",
    ")\n",
    "\n",
    "table(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City          object\n",
       "Employee      object\n",
       "Job_Title     object\n",
       "Salary         int64\n",
       "Rank         float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data types \n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using groupby and apply together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+-----------------+----------------------+------------------------+\n",
      "| customer_id | total_orders | avg_order_value | most_common_category | pct_change_order_value |\n",
      "+-------------+--------------+-----------------+----------------------+------------------------+\n",
      "|     101     |     0.5      |       0.0       |     Electronics      |          1.0           |\n",
      "|     102     |     0.0      |       1.0       |      Furniture       |   0.7714285714285714   |\n",
      "|     103     |     1.0      |       0.05      |       Clothing       |          0.0           |\n",
      "+-------------+--------------+-----------------+----------------------+------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Sample DataFrame\n",
    "data = {\n",
    "    'customer_id': [101, 101, 101, 102, 102, 103, 103, 103, 103],\n",
    "    'order_id': [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "    'order_timestamp': [\n",
    "        '2023-01-01', '2023-01-15', '2023-02-01',\n",
    "        '2023-01-10', '2023-01-25',\n",
    "        '2023-01-05', '2023-01-20', '2023-02-01', '2023-02-15'\n",
    "    ],\n",
    "    'order_value': [100, 200, 150, 250, 300, 400, 100, 50, 75],\n",
    "    'product_category': [\n",
    "        'Electronics', 'Electronics', 'Furniture',\n",
    "        'Furniture', 'Furniture',\n",
    "        'Clothing', 'Clothing', 'Accessories', 'Clothing'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "# Convert 'order_timestamp' to datetime\n",
    "df['order_timestamp'] = pd.to_datetime(df['order_timestamp'])\n",
    "\n",
    "# Define a function for group-level calculations\n",
    "def customer_summary(group):\n",
    "    total_orders = len(group)\n",
    "    avg_order_value = group['order_value'].mean()\n",
    "    most_common_category = group['product_category'].mode().iloc[0]  # Mode can have ties, take the first one\n",
    "    first_order = group.sort_values('order_timestamp').iloc[0]['order_value']\n",
    "    last_order = group.sort_values('order_timestamp').iloc[-1]['order_value']\n",
    "    pct_change = (last_order - first_order) / first_order if first_order != 0 else np.nan\n",
    "\n",
    "    return pd.Series({\n",
    "        'total_orders': total_orders,\n",
    "        'avg_order_value': avg_order_value,\n",
    "        'most_common_category': most_common_category,\n",
    "        'pct_change_order_value': pct_change\n",
    "    })\n",
    "\n",
    "# Apply the custom function to each group\n",
    "customer_stats = df.groupby('customer_id').apply(customer_summary,include_groups=False)\n",
    "\n",
    "# Normalize the numeric columns to a [0, 1] range\n",
    "def normalize(series):\n",
    "    return (series - series.min()) / (series.max() - series.min())\n",
    "\n",
    "numeric_cols = ['total_orders', 'avg_order_value', 'pct_change_order_value']\n",
    "customer_stats[numeric_cols] = customer_stats[numeric_cols].apply(normalize)\n",
    "table(customer_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivot Table Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample dataset\n",
    "data = {\n",
    "    'Region': ['North', 'South', 'North', 'East', 'West', 'East', 'South', 'West', 'North', 'South'],\n",
    "    'Product': ['A', 'B', 'C', 'A', 'C', 'B', 'C', 'A', 'B', 'C'],\n",
    "    'Date': [\n",
    "        '2023-01-15', '2023-02-20', '2023-03-10', '2023-04-05', '2023-05-25',\n",
    "        '2023-06-15', '2023-07-10', '2023-08-20', '2023-09-15', '2023-10-10'\n",
    "    ],\n",
    "    'Sales': [500, 700, 200, 900, 300, 400, 600, 800, 1000, 750],\n",
    "    'Profit': [50, 100, 30, 120, 40, 60, 90, 110, 150, 100]\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert 'Date' to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Add a new column for quarter and year\n",
    "df['Year'] = df['Date'].dt.year\n",
    "df['Quarter'] = df['Date'].dt.to_period('Q')  # Example: '2023Q1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+---------+---------------------+-------+--------+------+---------+\n",
      "| index | Region | Product |         Date        | Sales | Profit | Year | Quarter |\n",
      "+-------+--------+---------+---------------------+-------+--------+------+---------+\n",
      "|   0   | North  |    A    | 2023-01-15 00:00:00 |  500  |   50   | 2023 |  2023Q1 |\n",
      "|   1   | South  |    B    | 2023-02-20 00:00:00 |  700  |  100   | 2023 |  2023Q1 |\n",
      "|   2   | North  |    C    | 2023-03-10 00:00:00 |  200  |   30   | 2023 |  2023Q1 |\n",
      "|   3   |  East  |    A    | 2023-04-05 00:00:00 |  900  |  120   | 2023 |  2023Q2 |\n",
      "|   4   |  West  |    C    | 2023-05-25 00:00:00 |  300  |   40   | 2023 |  2023Q2 |\n",
      "|   5   |  East  |    B    | 2023-06-15 00:00:00 |  400  |   60   | 2023 |  2023Q2 |\n",
      "|   6   | South  |    C    | 2023-07-10 00:00:00 |  600  |   90   | 2023 |  2023Q3 |\n",
      "|   7   |  West  |    A    | 2023-08-20 00:00:00 |  800  |  110   | 2023 |  2023Q3 |\n",
      "|   8   | North  |    B    | 2023-09-15 00:00:00 |  1000 |  150   | 2023 |  2023Q3 |\n",
      "|   9   | South  |    C    | 2023-10-10 00:00:00 |  750  |  100   | 2023 |  2023Q4 |\n",
      "+-------+--------+---------+---------------------+-------+--------+------+---------+\n"
     ]
    }
   ],
   "source": [
    "table(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------------+------------------------+------------------------+-----------------------+-------------------------+--------------------------+--------------------------+-------------------------+\n",
      "| ('Product', '') | ('Sales_Sum', 'East') | ('Sales_Sum', 'North') | ('Sales_Sum', 'South') | ('Sales_Sum', 'West') | ('Profit_Mean', 'East') | ('Profit_Mean', 'North') | ('Profit_Mean', 'South') | ('Profit_Mean', 'West') |\n",
      "+-----------------+-----------------------+------------------------+------------------------+-----------------------+-------------------------+--------------------------+--------------------------+-------------------------+\n",
      "|        A        |         900.0         |         500.0          |          nan           |         800.0         |          120.0          |           50.0           |           nan            |          110.0          |\n",
      "|        B        |         400.0         |         1000.0         |         700.0          |          nan          |           60.0          |          150.0           |          100.0           |           nan           |\n",
      "|        C        |          nan          |         200.0          |         1350.0         |         300.0         |           nan           |           30.0           |           95.0           |           40.0          |\n",
      "+-----------------+-----------------------+------------------------+------------------------+-----------------------+-------------------------+--------------------------+--------------------------+-------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Group by Region and Product, aggregate Sales and Profit\n",
    "grouped = (\n",
    "    df.groupby(['Region', 'Product'])\n",
    "    .agg(\n",
    "        Sales_Sum=('Sales', 'sum'),\n",
    "        Profit_Mean=('Profit', 'mean')\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Pivot the grouped DataFrame\n",
    "pivot_table = grouped.pivot(\n",
    "    index=['Product'],\n",
    "    columns=['Region'],\n",
    "    values=['Sales_Sum', 'Profit_Mean']\n",
    ")\n",
    "\n",
    "# Flatten the multi-level columns\n",
    "table(pivot_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+---------+-------+--------+----------+\n",
      "| index | Region | Product | Sales | Profit | Quantity |\n",
      "+-------+--------+---------+-------+--------+----------+\n",
      "|   0   | North  |    A    |  100  |   10   |    5     |\n",
      "|   1   | North  |    B    |  200  |   20   |    10    |\n",
      "|   2   | South  |    A    |  150  |   15   |    8     |\n",
      "|   3   | South  |    B    |  250  |   25   |    12    |\n",
      "|   4   |  East  |    A    |  300  |   30   |    15    |\n",
      "|   5   |  East  |    B    |  400  |   40   |    20    |\n",
      "+-------+--------+---------+-------+--------+----------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Region': ['North', 'North', 'South', 'South', 'East', 'East'],\n",
    "    'Product': ['A', 'B', 'A', 'B', 'A', 'B'],\n",
    "    'Sales': [100, 200, 150, 250, 300, 400],\n",
    "    'Profit': [10, 20, 15, 25, 30, 40],\n",
    "    'Quantity': [5, 10, 8, 12, 15, 20]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "table(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Profit</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Quantity</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product</th>\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>Total</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>Total</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>East</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20</td>\n",
       "      <td>300.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>North</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12</td>\n",
       "      <td>150.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Total</td>\n",
       "      <td>18.333333</td>\n",
       "      <td>28.333333</td>\n",
       "      <td>23.333333</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20</td>\n",
       "      <td>550.0</td>\n",
       "      <td>850.0</td>\n",
       "      <td>1400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Region     Profit                       Quantity              Sales  \\\n",
       "Product                 A          B      Total        A     B Total      A   \n",
       "0         East  30.000000  40.000000  35.000000     15.0  20.0    20  300.0   \n",
       "1        North  10.000000  20.000000  15.000000      5.0  10.0    10  100.0   \n",
       "2        South  15.000000  25.000000  20.000000      8.0  12.0    12  150.0   \n",
       "3        Total  18.333333  28.333333  23.333333     15.0  20.0    20  550.0   \n",
       "\n",
       "                      \n",
       "Product      B Total  \n",
       "0        400.0   700  \n",
       "1        200.0   300  \n",
       "2        250.0   400  \n",
       "3        850.0  1400  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----+-------+---+---+\n",
      "| index |  A  |  B  |   C   | D | E |\n",
      "+-------+-----+-----+-------+---+---+\n",
      "|   0   | foo | one | small | 1 | 2 |\n",
      "|   1   | foo | one | large | 2 | 4 |\n",
      "|   2   | foo | one | large | 2 | 5 |\n",
      "|   3   | foo | two | small | 3 | 5 |\n",
      "|   4   | foo | two | small | 3 | 6 |\n",
      "|   5   | bar | one | large | 4 | 6 |\n",
      "|   6   | bar | one | small | 5 | 8 |\n",
      "|   7   | bar | two | small | 6 | 9 |\n",
      "|   8   | bar | two | large | 7 | 9 |\n",
      "+-------+-----+-----+-------+---+---+\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "      \"A\": [\"foo\", \"foo\", \"foo\", \"foo\", \"foo\",\"bar\", \"bar\", \"bar\", \"bar\"],\n",
    "      \"B\": [\"one\", \"one\", \"one\", \"two\", \"two\",\"one\", \"one\", \"two\", \"two\"],\n",
    "      \"C\": [\"small\", \"large\", \"large\", \"small\",\"small\", \"large\", \"small\", \"small\",\"large\"],\n",
    "      \"D\": [1, 2, 2, 3, 3, 4, 5, 6, 7],\n",
    "      \"E\": [2, 4, 5, 5, 6, 6, 8, 9, 9]\n",
    "})\n",
    "table(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>D</th>\n",
       "      <th colspan=\"3\" halign=\"left\">E</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <th>C</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">bar</th>\n",
       "      <th>large</th>\n",
       "      <td>5.500000</td>\n",
       "      <td>9</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>small</th>\n",
       "      <td>5.500000</td>\n",
       "      <td>9</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">foo</th>\n",
       "      <th>large</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>small</th>\n",
       "      <td>2.333333</td>\n",
       "      <td>6</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  D   E              \n",
       "               mean max      mean min\n",
       "A   C                                \n",
       "bar large  5.500000   9  7.500000   6\n",
       "    small  5.500000   9  8.500000   8\n",
       "foo large  2.000000   5  4.500000   4\n",
       "    small  2.333333   6  4.333333   2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_pivot = pd.pivot_table(\n",
    "    df, \n",
    "    values=['D', 'E'], \n",
    "    index=['A', 'C'],\n",
    "    aggfunc={'D': \"mean\",'E': [\"min\", \"max\", \"mean\"]}\n",
    ")\n",
    "table_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## apply,map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-------------+-------+--------+\n",
      "| index | Product |   Category  | Sales | Profit |\n",
      "+-------+---------+-------------+-------+--------+\n",
      "|   0   |    A    | Electronics |  500  |   50   |\n",
      "|   1   |    B    |  Groceries  |  150  |   20   |\n",
      "|   2   |    C    |   Clothing  |  200  |   30   |\n",
      "|   3   |    D    | Electronics |  800  |   80   |\n",
      "|   4   |    E    |  Groceries  |  100  |   10   |\n",
      "+-------+---------+-------------+-------+--------+\n",
      "+-------+---------+-------------+-------+--------+----------------+\n",
      "| index | Product |   Category  | Sales | Profit | Adjusted_Sales |\n",
      "+-------+---------+-------------+-------+--------+----------------+\n",
      "|   0   |    A    | Electronics |  500  |   50   |     455.0      |\n",
      "|   1   |    B    |  Groceries  |  150  |   20   |     142.5      |\n",
      "|   2   |    C    |   Clothing  |  200  |   30   |     163.0      |\n",
      "|   3   |    D    | Electronics |  800  |   80   |     728.0      |\n",
      "|   4   |    E    |  Groceries  |  100  |   10   |      95.0      |\n",
      "+-------+---------+-------------+-------+--------+----------------+\n"
     ]
    }
   ],
   "source": [
    "# Sample dataset\n",
    "data = {\n",
    "    'Product': ['A', 'B', 'C', 'D', 'E'],\n",
    "    'Category': ['Electronics', 'Groceries', 'Clothing', 'Electronics', 'Groceries'],\n",
    "    'Sales': [500, 150, 200, 800, 100],\n",
    "    'Profit': [50, 20, 30, 80, 10]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "table(df)\n",
    "\n",
    "# External mapping for discounts\n",
    "discounts = {'Electronics': 0.1, 'Groceries': 0.05, 'Clothing': 0.2}\n",
    "\n",
    "# Apply a complex function row-wise to calculate adjusted sales\n",
    "df['Adjusted_Sales'] = df.apply(\n",
    "    lambda row: row['Sales'] * (1 - discounts.get(row['Category'], 0)) + (row['Profit'] * 0.1 if row['Profit'] > 20 else 0),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "table(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+---------+---------+\n",
      "| index | Math | Science | History |\n",
      "+-------+------+---------+---------+\n",
      "|   0   |  95  |   90.0  |   88.0  |\n",
      "|   1   |  85  |   80.0  |   78.0  |\n",
      "|   2   |  75  |   70.0  |   68.0  |\n",
      "|   3   |  65  |   60.0  |   58.0  |\n",
      "|   4   |  87  |   nan   |   nan   |\n",
      "+-------+------+---------+---------+\n",
      "+-------+------+---------+---------+\n",
      "| index | Math | Science | History |\n",
      "+-------+------+---------+---------+\n",
      "|   0   |  A   |    A    |    B    |\n",
      "|   1   |  B   |    B    |    C    |\n",
      "|   2   |  C   |    C    |    D    |\n",
      "|   3   |  D   |    D    |    D    |\n",
      "|   4   |  B   |   N/A   |   N/A   |\n",
      "+-------+------+---------+---------+\n"
     ]
    }
   ],
   "source": [
    "# Sample DataFrame\n",
    "data = {\n",
    "    'Math': [95, 85, 75, 65, 87],\n",
    "    'Science': [90, 80, 70, 60, np.nan],\n",
    "    'History': [88, 78, 68, 58, np.nan]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "table(df)\n",
    "\n",
    "# Apply a grading scale\n",
    "def grade(value):\n",
    "    if pd.isna(value):\n",
    "        return 'N/A'\n",
    "    elif value >= 90:\n",
    "        return 'A'\n",
    "    elif value >= 80:\n",
    "        return 'B'\n",
    "    elif value >= 70:\n",
    "        return 'C'\n",
    "    else:\n",
    "        return 'D'\n",
    "\n",
    "# Use applymap for element-wise grading\n",
    "graded_df = df.map(grade)\n",
    "\n",
    "table(graded_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "+-------+---------+--------+-------+--------+------+--------------------+\n",
      "| index | Product | Region | Sales | Profit | Tax  |     Net_Sales      |\n",
      "+-------+---------+--------+-------+--------+------+--------------------+\n",
      "|   0   |    A    | North  |  500  |   50   | 0.1  |       455.0        |\n",
      "|   1   |    B    | South  |  300  |   30   | 0.08 |       279.0        |\n",
      "|   2   |    C    |  East  |  400  |   60   | 0.05 |       386.0        |\n",
      "|   3   |    D    |  West  |  250  |   40   | 0.07 | 236.49999999999997 |\n",
      "+-------+---------+--------+-------+--------+------+--------------------+\n",
      "\n",
      "Categorized DataFrame:\n",
      "+-------+---------+--------+--------+--------+-----+-----------+\n",
      "| index | Product | Region | Sales  | Profit | Tax | Net_Sales |\n",
      "+-------+---------+--------+--------+--------+-----+-----------+\n",
      "|   0   |    A    | North  |  High  |  Low   | Low |    High   |\n",
      "|   1   |    B    | South  | Medium |  Low   | Low |   Medium  |\n",
      "|   2   |    C    |  East  |  High  |  Low   | Low |    High   |\n",
      "|   3   |    D    |  West  | Medium |  Low   | Low |   Medium  |\n",
      "+-------+---------+--------+--------+--------+-----+-----------+\n"
     ]
    }
   ],
   "source": [
    "# Sample dataset\n",
    "data = {\n",
    "    'Product': ['A', 'B', 'C', 'D'],\n",
    "    'Region': ['North', 'South', 'East', 'West'],\n",
    "    'Sales': [500, 300, 400, 250],\n",
    "    'Profit': [50, 30, 60, 40]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Use map to map regions to sales tax\n",
    "region_tax = {'North': 0.1, 'South': 0.08, 'East': 0.05, 'West': 0.07}\n",
    "df['Tax'] = df['Region'].map(region_tax)\n",
    "\n",
    "# Use apply to calculate net sales after tax and profit adjustment\n",
    "df['Net_Sales'] = df.apply(\n",
    "    lambda row: row['Sales'] * (1 - row['Tax']) + row['Profit'] * 0.1,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Use applymap to categorize all numerical values in the DataFrame\n",
    "def categorize(value):\n",
    "    if isinstance(value, (int, float)):\n",
    "        if value > 300:\n",
    "            return 'High'\n",
    "        elif value > 100:\n",
    "            return 'Medium'\n",
    "        else:\n",
    "            return 'Low'\n",
    "    return value\n",
    "\n",
    "categorized_df = df.map(categorize)\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "table(df)\n",
    "print(\"\\nCategorized DataFrame:\")\n",
    "table(categorized_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping row values into a list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+--------+\n",
      "| index | Category | Values |\n",
      "+-------+----------+--------+\n",
      "|   0   |    A     |   1    |\n",
      "|   1   |    A     |   2    |\n",
      "|   2   |    B     |   3    |\n",
      "|   3   |    B     |   4    |\n",
      "|   4   |    C     |   5    |\n",
      "+-------+----------+--------+\n",
      "+-------+----------+--------+\n",
      "| index | Category | Values |\n",
      "+-------+----------+--------+\n",
      "|   0   |    A     | [1, 2] |\n",
      "|   1   |    B     | [3, 4] |\n",
      "|   2   |    C     |  [5]   |\n",
      "+-------+----------+--------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'Category': ['A', 'A', 'B', 'B', 'C'],\n",
    "    'Values': [1, 2, 3, 4, 5]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "table(df)\n",
    "# Group rows by 'Category' and collect 'Values' into a list\n",
    "grouped = df.groupby('Category')['Values'].agg(list).reset_index()\n",
    "\n",
    "table(grouped)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## melt function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "+-------+---------+---------+----------+-------+\n",
      "| index | Product | January | February | March |\n",
      "+-------+---------+---------+----------+-------+\n",
      "|   0   |    A    |   100   |   110    |  120  |\n",
      "|   1   |    B    |   150   |   160    |  170  |\n",
      "|   2   |    C    |   200   |   210    |  220  |\n",
      "+-------+---------+---------+----------+-------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Original wide-format DataFrame\n",
    "data = {\n",
    "    'Product': ['A', 'B', 'C'],\n",
    "    'January': [100, 150, 200],\n",
    "    'February': [110, 160, 210],\n",
    "    'March': [120, 170, 220],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "table(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Melted DataFrame:\n",
      "+-------+---------+----------+-------+\n",
      "| index | Product |  Month   | Sales |\n",
      "+-------+---------+----------+-------+\n",
      "|   0   |    A    | January  |  100  |\n",
      "|   1   |    B    | January  |  150  |\n",
      "|   2   |    C    | January  |  200  |\n",
      "|   3   |    A    | February |  110  |\n",
      "|   4   |    B    | February |  160  |\n",
      "|   5   |    C    | February |  210  |\n",
      "|   6   |    A    |  March   |  120  |\n",
      "|   7   |    B    |  March   |  170  |\n",
      "|   8   |    C    |  March   |  220  |\n",
      "+-------+---------+----------+-------+\n"
     ]
    }
   ],
   "source": [
    "# Use melt to reshape the data\n",
    "melted_df = pd.melt(df, id_vars=['Product'], var_name='Month', value_name='Sales')\n",
    "\n",
    "print(\"\\nMelted DataFrame:\")\n",
    "table(melted_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
